{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SwitchTransformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7OkFZpmRfK5"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Hg1yWfBSGh2",
        "outputId": "dcd7a74e-5854-4b2b-8567-48e421f20f35"
      },
      "source": [
        "vocab_size=20000\n",
        "num_tokens_per_example=200\n",
        "(x_train,y_train),(x_val,y_val)=tf.keras.datasets.imdb.load_data(num_words=vocab_size)\n",
        "print(len(x_train),'Training sentences')\n",
        "print(len(x_val),'Validation sentences')\n",
        "\n",
        "x_train=tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
        "                               maxlen=num_tokens_per_example,padding='post',)\n",
        "x_val=tf.keras.preprocessing.sequence.pad_sequences(x_val,\n",
        "                             maxlen=num_tokens_per_example,padding='post')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25000 Training sentences\n",
            "25000 Validation sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3zhxMTcTY1c",
        "outputId": "8c0dbca3-8940-450b-ac59-01718d4a3d7f"
      },
      "source": [
        "embed_dim=32\n",
        "num_heads=2\n",
        "ff_dim=32\n",
        "num_experts=10\n",
        "batch_size=50\n",
        "learning_rate=0.001\n",
        "dropout_rate=0.25\n",
        "num_epochs=3\n",
        "num_tokens_per_batch=(batch_size*num_tokens_per_example)\n",
        "print(f'Number of tokens per batch:{num_tokens_per_batch}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tokens per batch:10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3DgIknjT_a2"
      },
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "  def __init__(self,maxlen,vocab_size,embed_dim):\n",
        "    super(TokenAndPositionEmbedding,self).__init__()\n",
        "    self.token_emb=layers.Embedding(vocab_size,embed_dim)\n",
        "    self.pos_emb=layers.Embedding(maxlen,embed_dim)\n",
        "\n",
        "  def call(self,x):\n",
        "    maxlen=tf.shape(x)[-1]\n",
        "    positions=tf.range(start=0,limit=maxlen,delta=1)\n",
        "    positions=self.pos_emb(positions)\n",
        "    x=self.token_emb(x)\n",
        "    return x+positions  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8GRZCcLU4Mu"
      },
      "source": [
        "#Mixture of Experts\n",
        "def create_feedforward_network(ff_dim,name=None):\n",
        "  return tf.keras.Sequential([\n",
        "         layers.Dense(ff_dim,activation='relu'),\n",
        "         layers.Dense(ff_dim)],name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cik9UmwHVlVE"
      },
      "source": [
        "#This is an auxiliary loss to encourage a balanced load across experts\n",
        "def load_balanced_loss(router_probs,expert_mask):\n",
        "  num_experts=tf.shape(expert_mask)[-1]\n",
        "  density=tf.reduce_mean(expert_mask,axis=0)\n",
        "  density_proxy=tf.reduce_mean(router_probs,axis=0)\n",
        "  loss=tf.reduce_mean(density_proxy*density)*tf.cast((num_experts**2),tf.float32)\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v32ASEc7Xjtf"
      },
      "source": [
        "class Router(layers.Layer):\n",
        "  def __init__(self,num_experts,expert_capacity):\n",
        "    self.num_experts=num_experts\n",
        "    self.route=layers.Dense(num_experts)\n",
        "    self.expert_capacity=expert_capacity\n",
        "    super(Router,self).__init__()\n",
        "\n",
        "  def call(self,inputs,training=False):\n",
        "    #inputs shape:[tokens_per_batch,embed_dim]=[10000,32]\n",
        "    #router_logits shape:[10000,10]\n",
        "    router_logits=self.route(inputs)\n",
        "\n",
        "    if training:\n",
        "      #Add noise for exploration across experts\n",
        "      router_logits+=tf.random.uniform(shape=router_logits.shape,minval=0.9,maxval=1.1)\n",
        "\n",
        "    router_probs=keras.activations.softmax(router_logits,axis=-1)\n",
        "    expert_gate,expert_index=tf.math.top_k(router_probs,k=1)\n",
        "    #expert_mask shape:[10000,10]\n",
        "    expert_mask=tf.one_hot(expert_index,depth=self.num_experts)\n",
        "    #Compute load balancing loss\n",
        "    aux_loss=load_balanced_loss(router_probs,expert_mask)\n",
        "    self.add_loss(aux_loss)\n",
        "\n",
        "    position_in_expert=tf.cast(tf.math.cumsum(expert_mask,axis=0)*expert_mask,tf.dtypes.int32)\n",
        "    #Keep only tokens that fit within expert capacity\n",
        "    expert_mask*=tf.cast(tf.math.less(tf.cast(position_in_expert,tf.dtypes.int32),self.expert_capacity),\n",
        "                         tf.dtypes.float32,)\n",
        "    expert_mask_flat=tf.reduce_sum(expert_mask,axis=-1)\n",
        "    #Mask out the experts that have overflowed the expert capacity\n",
        "    expert_gate*=expert_mask_flat\n",
        "    #Combine expert outputs and scaling with router probability\n",
        "    #combined_tensor shape:[tokens_per_batch,num_experts,expert_capacity]=[10000,10,10000//10]\n",
        "    combined_tensor=tf.expand_dims(expert_gate\n",
        "                                   *expert_mask_flat\n",
        "                                   *tf.squeeze(tf.one_hot(expert_index,depth=self.num_experts),1),\n",
        "                                   -1)*tf.squeeze(tf.one_hot(position_in_expert,depth=self.expert_capacity),1)\n",
        "    dispatch_tensor=tf.cast(combined_tensor,tf.dtypes.float32)\n",
        "\n",
        "    return dispatch_tensor,combined_tensor\n",
        "                               "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYKiStjPGsRB",
        "outputId": "f83d5cf5-b531-48d7-912b-bd3358486fc3"
      },
      "source": [
        "expert_mask=tf.one_hot([1,2,1,3],depth=4)  #(10000,)\n",
        "print(expert_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]], shape=(4, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAOIEqWJJK97",
        "outputId": "0cb03c20-49c4-4eed-f958-889ae8071189"
      },
      "source": [
        "position_in_expert=tf.math.cumsum(expert_mask,axis=0)*expert_mask\n",
        "print(position_in_expert)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 2. 0. 0.]\n",
            " [0. 0. 0. 1.]], shape=(4, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cu63tYPJ9Kp",
        "outputId": "ff3bbfd2-ca3a-420c-9f77-77d588a2eff1"
      },
      "source": [
        "expert_mask*=tf.cast(tf.math.less(tf.cast(position_in_expert,tf.dtypes.int32),2),\n",
        "                         tf.dtypes.float32,)\n",
        "print(expert_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]], shape=(4, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGzxF7hUMMnP",
        "outputId": "88145751-6e2d-4ee7-ae02-44e16e0d8532"
      },
      "source": [
        "expert_mask_flat=tf.reduce_sum(expert_mask,axis=-1)\n",
        "print(expert_mask_flat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([1. 1. 0. 1.], shape=(4,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZdEA-5QOZTc"
      },
      "source": [
        "class Switch(layers.Layer):\n",
        "  def __init__(self,num_experts,embed_dim,num_tokens_per_batch,capacity_factor=1):\n",
        "    self.num_experts=num_experts\n",
        "    self.embed_dim=embed_dim\n",
        "    self.experts=[\n",
        "         create_feedforward_network(embed_dim) for _ in range(num_experts)         \n",
        "    ]\n",
        "    self.expert_capacity=num_tokens_per_batch//self.num_experts\n",
        "    self.num_tokens_per_batch=num_tokens_per_batch\n",
        "    self.router=Router(self.num_experts,self.expert_capacity)\n",
        "    super(Switch,self).__init__()\n",
        "\n",
        "  def call(self,inputs):\n",
        "    batch_size=tf.shape(inputs)[0]\n",
        "    num_tokens_per_example=tf.shape(inputs)[1]\n",
        "\n",
        "    #inputs shape:[num_tokens_per_batch,embed_dim]\n",
        "    inputs=tf.reshape(inputs,[self.num_tokens_per_batch,self.embed_dim])\n",
        "    #dispatch_tensor shape:[expert_capacity,num_experts,tokens_per_batch]\n",
        "    #combine_tensor shape:[tokens_per_batch,num_experts,expert_capacity]\n",
        "    dispatch_tensor,combine_tensor=self.router(inputs)\n",
        "\n",
        "    #expert_inputs shape:[num_experts,expert_capacity,embed_dim]=[10,1000,16]\n",
        "    expert_inputs=tf.einsum(\"ab,acd->cdb\",inputs,dispatch_tensor)\n",
        "    expert_inputs=tf.reshape(expert_inputs,\n",
        "                     [self.num_experts,self.expert_capacity,self.embed_dim])\n",
        "     \n",
        "    \n",
        "    #Dispatch to experts\n",
        "    expert_input_list=tf.unstack(expert_inputs,axis=0)\n",
        "    expert_output_list=[self.experts[idx](expert_input)\n",
        "                       for idx,expert_input in enumerate(expert_input_list)]\n",
        "\n",
        "    #expert_outputs shape:[expert_capacity,num_experts,embed_dim]\n",
        "    expert_outputs=tf.stack(expert_output_list,axis=1)\n",
        "    #expert_outputs_combined shape:[tokens_per_batch,embed_dim]\n",
        "    expert_outputs_combined=tf.einsum(\"abc,xba->xc\",expert_outputs,combine_tensor)\n",
        "\n",
        "    #outputs_shape:[batch_size,num_tokens_per_example,embed_dim]\n",
        "    outputs=tf.reshape(expert_outputs_combined,\n",
        "                       [batch_size,num_tokens_per_example,self.embed_dim])\n",
        "    return outputs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1iWrG_iQNSw",
        "outputId": "1a300daf-3349-49ee-d762-fe609192848d"
      },
      "source": [
        "x = tf.reshape(tf.range(12), (3,4))\n",
        "print('x:',x)\n",
        "print(tf.unstack(x,axis=0))\n",
        "print(tf.unstack(x,axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: tf.Tensor(\n",
            "[[ 0  1  2  3]\n",
            " [ 4  5  6  7]\n",
            " [ 8  9 10 11]], shape=(3, 4), dtype=int32)\n",
            "[<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 1, 2, 3], dtype=int32)>, <tf.Tensor: shape=(4,), dtype=int32, numpy=array([4, 5, 6, 7], dtype=int32)>, <tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 8,  9, 10, 11], dtype=int32)>]\n",
            "[<tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 4, 8], dtype=int32)>, <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 5, 9], dtype=int32)>, <tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 2,  6, 10], dtype=int32)>, <tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 3,  7, 11], dtype=int32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpLnVkccYioa"
      },
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "  def __init__(self,embed_dim,num_heads,ffn,dropout_rate=0.1):\n",
        "    super(TransformerBlock,self).__init__()\n",
        "    self.att=layers.MultiHeadAttention(num_heads=num_heads,key_dim=embed_dim)\n",
        "    #The ffn can be either a standard feedforward network or a switch\n",
        "    #ayer with a Mixture of Experts.\n",
        "    self.ffn=ffn\n",
        "    self.layernorm1=layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2=layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.dropout1=layers.Dropout(dropout_rate)\n",
        "    self.dropout2=layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self,inputs,training):\n",
        "    attn_output=self.att(inputs,inputs)\n",
        "    attn_output=self.dropout1(attn_output,training=training)\n",
        "    out1=self.layernorm1(inputs+attn_output)\n",
        "    ffn_output=self.ffn(out1)\n",
        "    ffn_output=self.dropout2(ffn_output,training=training)\n",
        "    return self.layernorm2(out1+ffn_output)     \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v--sDr8cZeo"
      },
      "source": [
        "def create_classifier():\n",
        "  switch=Switch(num_experts,embed_dim,num_tokens_per_batch)\n",
        "  transformer_block=TransformerBlock(ff_dim,num_heads,switch)\n",
        "\n",
        "  inputs=layers.Input(shape=(num_tokens_per_example,))\n",
        "  embedding_layer=TokenAndPositionEmbedding(num_tokens_per_example,vocab_size,embed_dim)\n",
        "\n",
        "  x=embedding_layer(inputs)\n",
        "  x=transformer_block(x)\n",
        "  x=layers.GlobalAveragePooling1D()(x)\n",
        "  x=layers.Dropout(dropout_rate)(x)\n",
        "  x=layers.Dense(ff_dim,activation='relu')(x)\n",
        "  x=layers.Dropout(dropout_rate)(x)\n",
        "  outputs=layers.Dense(2,activation='softmax')(x)\n",
        "\n",
        "  classifier=tf.keras.Model(inputs=inputs,outputs=outputs)\n",
        "  return classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYV3ELvNdWgM"
      },
      "source": [
        "def run_experiment(classifier):\n",
        "  classifier.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "                     loss='sparse_categorical_crossentropy',\n",
        "                     metrics=['accuracy'],)\n",
        "\n",
        "  history=classifier.fit(x_train,y_train,\n",
        "                         batch_size=batch_size,\n",
        "                         epochs=num_epochs,\n",
        "                         validation_data=(x_val,y_val))\n",
        "\n",
        "  return history "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs2yG-Qfem3G",
        "outputId": "44465696-1f6a-4f5c-deb3-65c6b9f33f0c"
      },
      "source": [
        "classifier=create_classifier()\n",
        "run_experiment(classifier)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "500/500 [==============================] - 55s 101ms/step - loss: 1.5484 - accuracy: 0.6948 - val_loss: 1.3211 - val_accuracy: 0.8571\n",
            "Epoch 2/3\n",
            "500/500 [==============================] - 51s 102ms/step - loss: 1.1973 - accuracy: 0.9255 - val_loss: 1.3148 - val_accuracy: 0.8700\n",
            "Epoch 3/3\n",
            "500/500 [==============================] - 51s 103ms/step - loss: 1.1443 - accuracy: 0.9508 - val_loss: 1.3472 - val_accuracy: 0.8648\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f20d38adad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-vnVaKfevNG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}